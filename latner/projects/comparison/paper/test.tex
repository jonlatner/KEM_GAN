
\section{Background}\label{sec:background}

As it was originally described, the idea of creating synthetic data was a theoretical process \cite{rubin1993statistical}.  To create synthetic data from actual data, all non-respondents in a survey are treated as missing values to be replaced with `imputed' values.  Given a dataset ($D$) with observations ($n$), there is a two-stage process.  First, a model for predicting a given outcome variable ($y$) given a set of background variables ($x$) is trained on the actual data.  Second, values of the original outcome variable are replaced by random values from the model of the outcome variable ($y^*$).  This process is then repeated so that all actual values are replaced by imputed values for every variable.  The result is a multiply-imputed synthetic dataset ($D^*$) that contains no values in the actual data, but looks structurally identical to the actual data, not only with respect to mean and variation within a given variable, but also correlations between variables.  

Despite the simplicity, implementing the theoretical process is more complicated than the description might suggest.  We highlight three issues.  One primary question is what method to use.  While the original application may have assumed some sort of parametric estimation using a linear or non-linear model, more recent research borrows from the machine learning literature, including Classification and Regression Trees (CART) \cite{reiter2005using}, Random Forests (RF) \cite{caiola2010random}, Support Vector Machines (SVM) \cite{drechsler2010using}, Bayesian Networks \cite{zhang2017privbayes}, and General Adversarial Networks (GANs) \cite{goodfellow2014generative}, among others.  

A second, related question is what package to use.  A statistical package that can be loaded into R or Python or another statistical software program that contains a synthetic data generator (SDG) is not the same thing as the method used by the SDG.  For example, the Python package Synthcity \cite{synthcity} contains multiple types of GANs (CTGAN, AdsGan, etc.) and Bayesian (PrivBayes, Bayesian Network) SDGs.  For SDGs using CART models, the Synthpop package \cite{nowok2016synthpop} is the most well known, but Synthpop is not CART and CART is not Synthpop.  It is important to distinguish the method from the package in order to reduce confusion when evaluating what SDG is right for what type of data.

Finally, a third question is how different SDGs approach real data with values that are missing, `messy' or extreme, and clustered.  While the idea of synthetic data comes from with the idea of imputing missing data, not all missing data are the same and it may be important to preserve missing values.  Relatedly, real data are inherently messy and this `messiness' is something we want to preserve in the synthetic data.  The concern is not only that the SDG may create data that are too clean when replacing values using random draws from a model, but also may create data that are too messy when trying to replicate extreme values.  Finally, while it is easy to label variables as categorical or continuous, some continuous variables can look like categorical variables and visa versa.  Users need to understand how different SDGs approach these common data problems.