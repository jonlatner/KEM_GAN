% \input{"../IAB/latex/TeX-Folienformat.tex"}
\input{"/Users/jonathanlatner/Google Drive/My Drive/IAB/latex/TeX-Folienformat.tex"}


\documentclass[t,8pt,utfx8]{beamer}
\usepackage{booktabs}
\usepackage{setspace}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{subcaption}
\setbeamertemplate{caption}[numbered]
\newcommand{\sprache}{\englisch}
\renewcommand{\thesubsection}{\alph{subsection})}
\usepackage[cal=pxtx, scr=dutchcal]{mathalpha}
\usepackage{forest}



\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}


\usepackage{listings}

% Define style for R code
\lstset{
  language=R,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue},
  stringstyle=\color{red},
  commentstyle=\color{green},
  showstringspaces=false,
  numbers=left,
  numberstyle=\tiny\color{gray},
  stepnumber=1,
  numbersep=5pt,
  breaklines=true,
  frame=single
}

\newcommand{\btVFill}{\vskip0pt plus 1filll}


\title{Buyer Beware: Understanding the trade-off between utility and risk in CART based models using simulation data}

\subtitle{UNECE Expert Meeting on Statistical Data Collection and Sources, \newline Barcelona, \newline 15-17 October 2025}

\author{Jonathan Latner, PhD \newline Dr. Marcel Neunhoeffer \newline Prof. Dr. Jörg Drechsler}

\newcounter{noauthorlines}
\setcounter{noauthorlines}{2} % Wert für 2 Autoren über 2 Zeilen. Ggf. anpassen

% %%%%%%%%%%%%%%
% Ende Anpassung
% %%%%%%%%%%%%%%

% \input{"../IAB/latex/TeX-Folienformatierung_CD_2019"}
\input{"/Users/jonathanlatner/Google Drive/My Drive/IAB/latex/TeX-Folienformatierung_CD_2019"}

% Modify the section in toc template to enumerate
\setbeamertemplate{section in toc}{%
    \inserttocsectionnumber.~\inserttocsection\par
}

% use for subsections
% \setbeamertemplate{subsection in toc}{}
\setbeamertemplate{subsection in toc}{%
    \setlength{\parskip}{1mm}
        \hskip2mm -- \hskip1mm\inserttocsubsection\par
}


\usepackage{colortbl}
\definecolor{lightgray}{gray}{0.9}

\usepackage{listings} %include R code
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\tiny,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                 
    columns=fullflexible,
    frame=single,
    tabsize=2
}
\lstset{style=mystyle}

\begin{document}

\frame[plain]{\titlepage}

\begin{spacing}{1.25}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c,plain]
\vskip-4mm
\begin{beamercolorbox}[wd=\boxwidth,ht=22.11mm]{transparent}%
    \vfill%
    \usebeamerfont{title}%
    \leftinsert%
    \MakeUppercase{Section \ref{sec:introduction}: Introduction} % <- Hier die Überschrift eintragen
\end{beamercolorbox}
\vskip-3mm
\pgfuseimage{rahmenlinie}
\end{frame}

\begin{frame}{Background and motivation}
% \scalebox{1}{\begin{minipage}{\textwidth}
\begin{itemize}
    \item Background:
    \begin{itemize}
        \item Synthetic data are increasingly used to share data while preserving privacy.
        \item Numerous synthetic data generators (SDGs) using variety of methods
        \item CART-based SDGs: high statistical utility with high privacy protection (Little et al., 2025)
    \end{itemize}
    \item Motivation:
    \begin{itemize}
        \item There is a general perception that generating synthetic data are easy.  
        \item It is not always clear if the resulting synthetic data are in fact providing privacy protection.
    \end{itemize}

\end{itemize}
% \end{minipage}}
\end{frame}


\begin{frame}{Overview}
% \scalebox{1}{\begin{minipage}{\textwidth}
\begin{itemize}
    \item Research question:
    \begin{itemize}
        % \item If that is true, how would we know?  
        \item Do common privacy measures capture disclosure risk in synthetic data generated by CART models?
    \end{itemize}
    \item Evaluate 3 types of privacy measures:
    \begin{enumerate}
        \item Identity disclosure risk
        \item Attribute disclosure risk
        \item Bayesian estimation of disclosure risk
    \end{enumerate}
    \item 2 types of data:
    \begin{enumerate}
        \item Simulated dataset (Reiter et al., 2014 design: 1,000 obs., 4 binary vars., unique case).
        \item Public survey data: Social Diagnosis 2011 (SD2011).
    \end{enumerate}
    \item Contributions: 
    \begin{itemize}
        % \item We show that CART-based models may produce synthetic data that sacrifices privacy protection for statistical utility.  
        \item Commonly used disclosure risk measures may not capture disclosure risk. 
        \item We propose some solutions for measuring disclosure risk (Bayesian).  
        \item More generally, users interested in empirical measures of privacy risk should be aware of the challenges we describe here.
    \end{itemize}
\end{itemize}
% \end{minipage}}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The data}\label{sec:data}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c,plain]
\vskip-4mm
\begin{beamercolorbox}[wd=\boxwidth,ht=22.11mm]{transparent}%
    \vfill%
    \usebeamerfont{title}%
    \leftinsert%
    \MakeUppercase{Section \ref{sec:data}: Generate simulated data (original and synthetic)
} % <- Hier die Überschrift eintragen
\end{beamercolorbox}
\vskip-3mm
\pgfuseimage{rahmenlinie}
\end{frame}

\begin{frame}[t]\frametitle{Original data set: simulated data}
\begin{itemize}
    \item Borrowing from Reiter et al. (2014), we create a data set with $n=1000$ and 4 dichotomous, categorical variables (i.e. dummy variables). 
    \item The first 999 observations are a random sample from all combinations of $var1(0,1), var2(0,1), var3(0,1), var4(0,1)$ except the last one
    \item The last (1000$^{th}$) observation is ($var1=1,var2=1,var3=1,var4=1$). 
    \item This is a vulnerable record in the original data that we would want to protect using synthetic data
    \item The value of the simulation is that we know there is a unique record because we created it.
\end{itemize}
\end{frame}

\begin{frame}[t]\frametitle{Synthetic data set}
\begin{itemize}
    \item Generate 1 synthetic data set from a CART-based SDG using the Synthpop package in R 
    \begin{itemize}
        \item We use the default settings and hyperparameter values and set a seed=$1237$. 
    \end{itemize}
    \item As a sensitivity test, we create 10 synthetic data sets from the original simulated data.  
\end{itemize}
\end{frame}

\begin{frame}[t]\frametitle{Compare original and 1 synthetic data copy (seed = 1237)}
\begin{minipage}{0.48\textwidth}
    \begin{figure}
        \centering
        \caption{Frequency}
        \includegraphics[width=\textwidth]{../../graphs/graph_cart_frequency_compare.pdf}
        \label{fig:frequency_compare}
    \end{figure}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
    \begin{figure}
        \centering
        \caption{Histogram}
        \includegraphics[width=\textwidth]{../../graphs/graph_cart_histogram_compare.pdf}
        \label{fig:histogram_compare}
    \end{figure}
\end{minipage}
\end{frame}

\begin{frame}[t]\frametitle{Compare histogram x 10 synthetic datasets}

\begin{figure}
    \caption{Multiple synthetic data sets does not reduce privacy risk}
    \resizebox{\textwidth}{!}{\includegraphics{../../graphs/graph_cart_histogram_compare_10_v1.pdf}}
    \label{fig:cart_histogram_compare_10}
\end{figure}

\end{frame}

\frame{\frametitle{Summary}
\begin{itemize}
    \item The problem: Synthetic data from CART models are disclosive in this simulation
    % \item The reason: 
    % \begin{itemize}
    %     \item A record can only be in the synthetic data if it is also in the original data (in this simulated data).   
    %     \item Or the opposite: if a record is not in the original data, then it can never be in the synthetic data.
    % \end{itemize}  
    \item Next section: Can an attacker identify the disclosure?
\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The attack}\label{sec:attack}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c,plain]
\vskip-4mm
\begin{beamercolorbox}[wd=\boxwidth,ht=22.11mm]{transparent}%
    \vfill%
    \usebeamerfont{title}%
    \leftinsert%
    \MakeUppercase{Section \ref{sec:attack}: The attack
} % <- Hier die Überschrift eintragen
\end{beamercolorbox}
\vskip-3mm
\pgfuseimage{rahmenlinie}

\end{frame}

\begin{frame}[t]\frametitle{Describing the attack}

\begin{itemize}
    \item We assume a `strong' attacker similar to the attack model in differential privacy (DP). 
    \item An attacker has the following knowledge
    \begin{itemize}
        \item Knows the SDG model type (i.e. sequential CART).
        \item Knowledge of the first 999 observations in the original data except the last one (1000$^{th}$).  
        \item The 16 possible combinations that the last one could be.
    \end{itemize}
    \item The attacker sees the synthetic data
    \item The attacker runs CART on the original data for all of the 16 different possibilities about the last record.
    \item Compares synthetic data from the attack to the released synthetic data  
    \item Then they update their beliefs about what the last record could be
\end{itemize}

\end{frame}

\begin{frame}[t]\frametitle{Histogram of 16 worlds x 10 synthetic datasets}

\begin{figure}
    \caption{}
    \vskip -4mm
    \resizebox{.9\textwidth}{!}{\includegraphics{../../graphs/graph_attacker_default_v1.pdf}}
    \label{fig:attacker_default}
\end{figure}


\end{frame}



\frame{\frametitle{Summary}
\begin{itemize}
    \item In our attack with our assumptions, the attacker can easily identify the last record
    % \item The reason (to repeat): 
    % \begin{itemize}
    %     \item A record can only be in the synthetic data if it is also in the original data (in this simulated data).   
    %     \item Or the opposite: if a record is not in the original data, then it can never be in the synthetic data.
    % \end{itemize}  
    \item Next section: Can we measure this disclosure risk?
\end{itemize}

}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Measuring disclosure risk}\label{sec:disclosure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c,plain]
\vskip-4mm
\begin{beamercolorbox}[wd=\boxwidth,ht=22.11mm]{transparent}%
    \vfill%
    \usebeamerfont{title}%
    \leftinsert%
    \MakeUppercase{Section \ref{sec:disclosure}: Measuring disclosure risk
} % <- Hier die Überschrift eintragen
\end{beamercolorbox}
\vskip-3mm
\pgfuseimage{rahmenlinie}
\end{frame}

\begin{frame}[t]\frametitle{Three disclosure risk measures}

\begin{itemize}
    \item 2x Common disclosure risk measures reflect the current state of the art  (Raab et al., 2025)
    \begin{itemize}
        \item Identity risk ($repU$): the ability to identify individuals in the data from a set of known characteristics or `keys' ($q$).  
        \begin{itemize}
            \item  $q=var1(0,1), var2(0,1), var3(0,1)$ 
            % \item Disclosure risk is how often uniqueness in the synthetic data translates into uniqueness in the original data
            % \item This should be 0 because these three attributes yield $2^3 = 8$ possible combinations, none of which are unique in the dataset
        \end{itemize}
        \item Attribute risk ($DiSCO$): the ability to find out from the keys ($q$) something, not previously known or `target' ($t$)
        \begin{itemize}
            \item $t=var4(0,1)$
            % \item Disclosure risk is the proportion of records in the synthetic data with the same level of $t$ for a given set of $q$
            % \item This should be $>0$ because when $q=111$, there is a unique record if $t=1$. 
        \end{itemize}
    \end{itemize}
    \item 1x Alternative disclosure risk measure
    \begin{itemize}
        \item Bayesian approach (Reiter et al., 2014)
        \begin{itemize}
            \item For example, the attacker has a prior (e.g., uniform distribution)
            \item If posterior probability is close to the prior, little or no new information is revealed.  
            \item If posterior probability is substantially larger, the intruder has learned something about the last or unique record.  
        \end{itemize}
        % \item In our data this should be $>0$, i.e. positive
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[t]\frametitle{Results disclosure risk measures}
\begin{minipage}[t]{0.48\textwidth}
    \begin{table}[]
        \centering
        \caption{x 1 synthetic data set (seed = 1237)}
        \resizebox{\textwidth}{!}{\input{../../tables/table_disclosure_risk_1_mn.tex}}
        \label{table:disclosure_risk_1}
    \end{table}

% \begin{itemize}
%     \small
%     \item $DiSCO > 0$ only when $t$ is constant within the set of records sharing the same $q$


%     \item If there is at least one unique record in the synthetic data, then there is no attribute disclosure risk because there are 2 values of $t$ within $q$ (0,1).  
%     \item At the same time, if a synthetic data set is released without the unique record, then there is an attribute disclosure risk because there is only 1 value of $t$ within $q$ (1).
% \end{itemize}

\end{minipage}%
\hfill%
\begin{minipage}[t]{0.48\textwidth}

    \begin{table}[]
        \centering
        \caption{x 10 synthetic data sets}
        \rowcolors{1}{white}{lightgray}
        \resizebox{\textwidth}{!}{\input{../../tables/table_disclosure_risk_10_mn.tex}}
        \label{table:disclosure_risk_10}
    \end{table}

    % \begin{itemize}
    %     \small
    %     \item $DiSCO = 6.6$.  This is the equivalent 66/1000 ((65/1000 = var1=1,var2=2,var3=1)+(1/1000 = var1=1,var2=2,var3=1,var4=1))
    % \end{itemize}

\end{minipage}
\end{frame}



\frame{\frametitle{Summary}
\begin{itemize}
    \item Common privacy measures do not capture the disclosure risk in our data
    \item However (and this is the point): We know there is a problem (because we created it)
    \item Only Bayesian approach captures disclosure risk
    % \begin{itemize}
    %     \item Risk is 1 whenever at least one record equal to $(1,1,1,1)$ appears in the synthetic data. 
    %     \item Risk $>0$ when (1,1,1,1)  does not reappear in the synthetic data. 
    % \end{itemize}

\end{itemize}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Is this scenario realistic?}\label{sec:reality}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c,plain]
\vskip-4mm
\begin{beamercolorbox}[wd=\boxwidth,ht=22.11mm]{transparent}%
    \vfill%
    \usebeamerfont{title}%
    \leftinsert%
    \MakeUppercase{Section \ref{sec:reality}: Is this scenario realistic?
} % <- Hier die Überschrift eintragen
\end{beamercolorbox}
\vskip-3mm
\pgfuseimage{rahmenlinie}

\end{frame}

\frame{\frametitle{Real world data (SD2011)}

\begin{itemize}
    \item Replicate the approach the authors of Synthpop (Raab, 2024; Raab et al., 2024)  
    \item Data are from Social Diagnosis 2011 (SD2011). 
    \item Measure disclosure risk
    \begin{itemize}
         \item 4 keys ($q$): \texttt{sex} \texttt{age} \texttt{region} \texttt{placesize}.
         \item 1 target ($t$): \texttt{depress}
     \end{itemize}
    \item  Generate 5 synthetic copies with a `bad' synthesizer
    \begin{itemize}
        \item Generate 5 synthetic copies using CART with default parameters in Synthpop
        \item Modify synthetic copies by setting $t=0$, or constant for all observations in all 5 synthetic data sets.
        \item Therefore, we know risk declined (because we reduced it).
    \end{itemize}
    \item Do common disclosure risk measures ($repU$, $DiSCO$) capture this decline? 
    \begin{itemize}
        \item Why not Bayesian approach?  High-dimensional, real data is too computationally complex.  Only good for low-dimensional data
    \end{itemize}

\end{itemize}


}

\begin{frame}[t]\frametitle{Results}

\begin{table}[!h]
    \centering
    \caption{Risk measures for \texttt{depress} from keys: \texttt{sex}, \texttt{age}, \texttt{region}, \texttt{placesize} (SD2011)}
    % \rowcolors{1}{white}{lightgray}
    \input{../../tables/table_disclosure_risk_sd2011_v2.tex}
    \label{tab:attribute_risk_sd2011}
\end{table}



\end{frame}

\begin{frame}[t]\frametitle{Summary}

\begin{itemize}
    \item When we modify synthetic data to reduce attribute disclosure risk, $DiSCO$ measure increases
    \item The package authors are aware of the problem that the $DiSCO$ measure of attribute disclosure risk can indicate a high level of risk for a target variable where a high proportion of records have one level (Raab et al., 2025).
    \item This is good, but our example illustrates a more general concern: $DiSCO$ may mismeasure risk by indicating it is rising, when it declined
\end{itemize}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}\label{sec:conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c,plain]
\vskip-4mm
\begin{beamercolorbox}[wd=\boxwidth,ht=22.11mm]{transparent}%
    \vfill%
    \usebeamerfont{title}%
    \leftinsert%
    \MakeUppercase{Section \ref{sec:conclusion}: Conclusion} % <- Hier die Überschrift eintragen
\end{beamercolorbox}
\vskip-3mm
\pgfuseimage{rahmenlinie}
\end{frame}

\begin{frame}[t]\frametitle{Summary}

\begin{itemize}
    \item Key contribution: Common disclosure risk metrics may fail to detect or even misstate risk.  
    \begin{itemize}
        \item Suggests no risk, when we know there is a risk (simulation data)
        \item Suggests risk is rising, when we know it declined (real data)
        \item Bayesian approach can be a good solution, but only in low-dimensional data
    \end{itemize}
    \item Key point: users must understand how disclosure risk measures operate.  
    \begin{itemize}
        \item Empirical disclosure risk measures always have problems
        \item There is no one-size-fits-all solution.  
    \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}[t]\frametitle{Thank you}

Jonathan Latner: \url{jonathan.latner@iab.de} \\

Reproducible code: \url{https://github.com/jonlatner/KEM\_GAN/tree/main/latner/projects/simulation} 


\end{frame}

\end{spacing}
\end{document}

